---
date: 7 July 2022
title: Call for Contributions
description: Algocount Final Event
imgUrl: ./cfp.jpg
resUrl: 
customUrl: algocount-final-event
type: read more
pageName: events
---

### Call for contributions
# Everyday algorithms
## Algocount Final Event — 7 July 2022

This international conference aims at exploring the role algorithms play in the formation of public opinion from a multi-disciplinary perspective. Set in the context of the *Algocount*, which seeks to expand the current understanding of how recommendation and personalization algorithms are perceived as key mediators in the access to news and informational content by ordinary users, the conference welcomes contributions that critically reflect on the unfolding of what we define as the ‘algorithmic public opinion’. 

With this term we intend to grasp the algorithmically-driven processes by which a certain issue becomes a salient matter of public opinion, and the central role recommendation and personalization algorithms play as gatekeeping infrastructures through which individuals access information, produce their opinions and consolidate their social and political views. From the the moment it comes into being, to when it reaches the wider public, information is prioritised, filtered and hidden across a thick mixture of elements that come together in the algorithmic infrastructure of social media and digital platforms (Moeller and Helberger, 2018; Bozdag and van der Hoven, 2015; Bozdag, 2013). This combines with the role played by third mediating parties — also known as data brokers. From the interaction among all of these elements, we contend, an algorithmic public opinion emerges – one that is unavoidably affected by the biased nature of technology (Friedman Kahn, Borning & Huldtgren, 2006) and its affordances; that concurs to the personalisation of online activity and the salience of issues of disinformation and misinformation; and may lead to the proliferation of partial or partisan information environments and situations of psychological and political polarisation (Settle, 2018; Dylko, Dolgov, Hoffman, Eckhart, Molina & Aaziz, 2018). Personalization, eventually, is personalised too: as such, while most seem to benefit from more or less varied and personalised content recommendations, others may end up in self-reinforcing echo chambers where information becomes redundant. Similarly, some personalization algorithms threaten to exploit individuals' vulnerabilities and facilitate politically dangerous content discovery pathways, often merely for purposes of engagement maximisation, and even contribute to creating addictive behaviours (Tufekci, 2018).

The emergence of an ‘algorithmic public opinion’, we maintain, bears huge social and cultural implications that require researchers to ramp up their efforts in expanding the existing understanding of algorithmic processes and the cultural conceptions surrounding them, without stopping at the ‘unknowability’ of black-boxed codes. Beyond the little public knowledge about the functioning of algorithms such as Facebook's News Feed, or YouTube's Related Videos, or the Google Search algorithm itself, in order to understand their relevance in the processes of public opinion creation there is a necessity to acknowledge these as social and cultural objects first. The fallout resulting from the already-mentioned Cambridge Analytica scandal, and the publication of a variety of documentaries that presented an exposè of the internal workings of social media platforms in relation to data management, content moderation and ethics, has given new space to discuss about reducing the opacity of algorithmic recommendation systems and enhancing their transparency. Within this debate the perceptions, opinions and understandings of algorithmic interventions in day-to-day information consumption and content filtering from the side of users matter as much as knowing about the code and mathematical formulations of these algorithms (Bucher, 2017). 


## Research questions
The conference invites participants from various intellectual traditions and streams of research, including media studies, sociology, information design, information science, science and technology studies, history of technology, computing and anthropology, human-computer interaction and political philosophy, to participate in an open debate around these issues. In particular, it sets to explore a number of key questions, such as (albeit not limited to) the following:

- How does an ‘algorithmic public opinion’ come into being? What imaginaries do users share or produce about algorithms and their functioning? Should users be able to weight the values embedded into the algorithmic content prioritisation? If so, how? Which are the most interesting and valuable experiments that support users’ autonomy of choice and control over personalization systems? Can the unfolding of an ‘algorithmic public opinion’ lead to an inversion of the “spiral of silence”, thus giving to certain social groups an excessively louder voice? Can alternative personalization systems exist? If so, how? 

- What does personalization actually mean, both conceptually and practically? How similar and diverse platforms employ personalization systems differently? To what extent do personalization algorithms affect the perception of the diffusion of certain opinions and worldviews? Is the inverse relationship between personalization accuracy and privacy a false dichotomy? How can we design personalization systems that support both diversity and individual relevance?

- Which methodological strategies can be put in place to identify, freeze, collect, and narrate invisible algorithmically-driven processes, and thus study their impact on everyday social situations?  Which are the possible shapes of algorithmic agency, considering its intertwinement with labour, people, environment and external infrastructures?

- Which languages are better suited to expose, visualise, materialise, stage and study algorithmic imaginaries? What can we learn from failures and not-successful experiences of algorithmic intermediation, recommendation and/or personalization?

- What role should journalists play in this context, and how is their work affected by it? How do public service media (e.g. RAI, BBC etc.) employ personalization systems? How can we preserve editorial principles such as universality, social relevance and serendipity in the personalization era? 

## Conference venue
The conference will take place at the *Museo Nazionale Scienza e Tecnologia Leonardo da Vinci of Milan* on 7 July 2022. Contributors are required to send in a 300-word abstract to the following email address: [algocountproject@gmail.com](mailto:algocountproject@gmail.com). 

The conference will comprise 4 panel presentations and 2 keynote sessions hosting internationally acclaimed scholars as speakers. A maximum of 10 papers will be selected for presentation. Preference will be given to speakers who plan to attend the conference in person, but a small number of remote presentations (no more than 1 per panel) may be included in the programme. Participation to the conference as an attendee (without presenting a paper) will be possible both in person and remotely, via Zoom. Up to 2 scholarships covering travel and accommodation expenses may be awarded to participants at an early-career stage or self-funded. If you belong to one of these categories, please enclose this information in your abstract submission. 

## Important dates
Abstracts are due by 8 April 2022 [AOE](https://time.is/Anywhere_on_Earth). These should include the author(s) name and position, a short title, and a clear indication of whether they plan to attend the conference in person or remotely. Acceptance notices will be given by 30 April 2022. 

## Conference organizing committee
Alessandro Gandini, Silvia Keeling, Urbano Reviglio, Diletta Huyskes, Luca Giuffrè (University of Milan); Michele Mauri, Beatrice Gobbo, Maria De Los Ángeles Briones Rojas (Politecnico di Milano, Density Design); Simona Casonato (Museo Nazionale Scienza e Tecnologia Leonardo da Vinci, Milan).
