[
  {
    "index": 1,
    "title": "PlacPlac",
    "description": "A new dissemination format for Digital Methods research",
    "imgUrl": "./placplac.jpg",
    "imgUrl2": "",
    "imgDida": "",
    "resUrl": "https://github.com/densitydesign/placplac",
    "file": "",
    "content": "\n# PlacPlac\n\n Part of the Algocount research has been carried on during a data sprint to study the public perception of algorithms in society. To present the research result to a broader audience, we developed PlacPlac, a new dissemination format to store, stage, and access the results of data sprints after research activities. The format is based on a tool called Plaplac, which is part of a research project. The tool is intended as a digital place that allows researchers to expose the research process with digital methods. The tool emphasizes telling the research process, articulating the content that reinforces the use of images, visualizations, audiovisual material, among others.\n\n",
    "type": "read more",
    "pageName": "materials"
  },
  {
    "index": 2,
    "title": "Literature Review",
    "description": "A literature review on the public perception of algorithms ",
    "imgUrl": "./litreview.jpg",
    "imgUrl2": "",
    "imgDida": "",
    "resUrl": "https://osf.io/preprints/socarxiv/m6zn8/",
    "file": "",
    "content": "\n# Literature Review\n\nIn the context of a society where digital technologies have come to pervasively intermediate most social, cultural and economic processes, algorithms represent an important socio-technical component of ‘the social’. Unsurprisingly, algorithms also hold an important role in the formation of public opinion. The way people access news and informational content, thus forming their political and social views, is now largely mediated by social media platforms. Their algorithms represent new types of gatekeepers that contribute in decisive ways to shape individual and collective access to information. In this literature review, we discuss the most relevant research concurring to the existence of what we define as an 'algorithmic public opinion', from an interdisciplinary perspective that brings together the sociology of media, critical algorithm studies and information design.\n\nThe text is publicly available on [SocArxiv](https://osf.io/preprints/socarxiv/m6zn8/) under a CC-By Attribution-NonCommercial-NoDerivatives 4.0 International License.",
    "type": "read more",
    "pageName": "materials"
  },
  {
    "index": 3,
    "title": "Reporting Focus Groups",
    "description": "Results from five focus groups carried on during Summer 2021",
    "imgUrl": "./focusgroups.jpg",
    "imgUrl2": "",
    "imgDida": "",
    "resUrl": "",
    "file": "",
    "content": "### Reporting Focus Groups\n# Focus groups: exploring the algorithmic imaginaries of Italian social media users\n*Article by Luca Giuffrè*   \n*Focus groups conducted by Silvia Keeling and Alessandro Gerosa*\n\nOne of the main goals of the ALGOCOUNT research project is to assess perception, knowledge and trust towards algorithms embedded within social media for content recommendation. In order to address this issue, the research team has conducted six focus groups involving 33 Italian social media users equally distributed in terms of gender, education and age (between 18 and 58 years old). This article aims at illustrating some of the main results emerging from the analysis.\n\n\nFor the vast majority of participants, social media represent the main gateway to access information. According to the number of accesses and time spent on them, these platforms are mostly used to keep up with the latest news and participate in peer-to-peer thematic groups (e.g. tips groups on Facebook). Although cross-checking informational sources and deep reading are generally held in online newspapers, the younger cohort is more prone to seek out affordable news online than the older participants, who still consider television as the most reliable media.\n\nNot only generational characteristics, but also personal opinions are relevant in influencing everyday informational diets on social media. As a matter of fact, subjective perceptions on these platforms tend to drive people to mistake their ideas for intrinsic features of the media itself. For example, some participants affirm that Facebook is the platform where “my parents would post onto”, that is an halfwaythrough statement between generational expectations and personal experiences.\n\nThese two aspects (generational and subjective features) set the frame into which users produce meanings, perceptions and values on social media. In fact, metrics represent a good way to observe particular values of the participants. For example, even if metrics are not considered relevant in the path of picking out online content, the social network (e.g. a friend’s name who liked a post) and relevant comments (e.g. influencers’ comments) appear to be more credible than the number of views — albeit the only exception is in the case of YouTube videos, more specifically tutorials.\n\nSimilarly, participants found it problematic to retrieve affordable news. Thus, awareness on news sources emerged as one of the most important values. Furthermore, while they reckon fake news as a relevant problem in contemporary society, participants tend to deny every kind of contact with them, although they can recall at least a story of “a friend that one day…”. In that case, sources have become a new social value through which people perceive the “Other”.\n\nThe key role of individual experiences sheds light in the second section of this article: the perception of algorithms. Above all, participants show an anecdotal awareness of algorithms mostly related to social media ads and recommended content. Furthermore, the algorithm's perception comes out as simple and — to some extent — raw, because it is almost entirely based on the “if… then” logic, that is the essential causal paradigm underneath flowcharts.\nHowever, stories told during the sessions show a variety of relationships with algorithms, mainly derived from an algorithmic acceptance threshold. More specifically, an algorithmic acceptance threshold refers to a cognitive line below which users are somehow in harmony with the algorithm, that is a low-stress and low-energy consumption relationship. Viceversa, above the threshold the human-algorithm interaction becomes conflicting and therefore highly consumptive in terms of cognitive energy.\n\nFor what concerns the observation of the algorithmic acceptance threshold, the phenomenon of *“glitches”* has been quite relevant for analytical purposes. A glitch is a peculiar event in which “something went wrong” during everyday life on social media. In those situations, people experience the presence of the recommendation algorithm and react in different ways. At this point, two main aspects emerged during the analysis: the relationship between humans and algorithms and the reactions related to their manifestation.\n\nIn order to explore the former, participants have been involved in a series of activities aimed at understanding the way through which they picture social media algorithms’ mechanism. For example, they have been asked to draw out an algorithm or to tell glitch stories as previously introduced. According to this, reference has been made to Bucher’s (2017) notion of “algorithmic imaginaries”, Siles et al.’s (2020) folk theories of algorithms and the vast research horizon that have recently implemented many theoretical approaches as well as methodologies fundamental to understanding human-algorithm interaction.\nIn this context, two main imaginaries have been observed: *human-deterministic* and *magical-anthropomorphic*. The first one, quite rare, is regulated by a causal modality of thinking, therefore the algorithm appears to be controllable and under human domain. On the other side, the most widespread cluster is typically characterised by an anthropomorphization of the algorithm, that is the perception of a quasi-human entity that decides the content seen by users. In these terms, user control over the algorithm might appear weaker. \nEventually, these imaginaries are useful to understand the agency role within the human-algorithmic relationship, although they are not closed clusters, as they still have some intersections.\n\nReactions to algorithms represent useful modalities to set a good cognitive balance towards the relationship with algorithms. In particular, glitches are relevant events that make people aware of algorithms and allow researchers to furtherly explore the consequent interaction. These have brought up two models attributable to the well-known Umberto Eco’s (1984) duality between *integrated* and *apocalyptic*. The integrated model includes individuals who reckon glitches as events in which algorithms catch users’ online behaviour improperly, giving back a faulty output. In some cases, their will of realignment has driven them to act in a way that teaches the algorithm what kind of content they want to see. Instead, in the apocalyptic model, people feel the algorithm’s glitches as an uncanny and upsetting experience, and are therefore more inclined to put exit-strategies in place. Furthermore, it is particularly interesting to observe the attempts to increase their perceived control over the platform through a system of tactics, as de Certeau would define them, aimed at coping with the algorithms. For example, by opting in the *I'm not interested* flag in order to hide specific categories of tweets or ads, using a software to disorientate the algorithm coping process, *lurking* a Facebook group as a form of non-participation.\n\nIn conclusion, the relationship with and the reaction to algorithms shed light on the relevance of algorithmic systems in regulating news circulation on social media. As a matter of fact, participants’ perception of news circulation relies in no small part on everyday interactions with algorithms. Yet, *good* information or news regarding niche themes is perceived as not fostered by these systems, whereas trending topics tend to be more related to algorithmic interventions as the algorithm is perceived to become more *precise*, regardless of the quality of the content itself. These perceptions bring up some contrasting opinions for what concerns AIs. For example, while few participants suggest algorithms should be even more efficient in terms of recommendation, others would rather systems programmed to prevent filter bubbles. Hence, they believe these should be more *democratic*, *ethical*, and *impartial*. While showing the development of contemporary public opinion, these necessities highlight the role of *black boxes* in the practice of everyday news circulation.  \n&nbsp;  \n&nbsp;    \n&nbsp;   \nBucher, T. (2017). The algorithmic imaginary: exploring the ordinary affects of Facebook algorithms. *Information, communication & society, 20(1)*, 30–44.  \n\nEco, U. (1984). *Apocalittici e integrati (Vol. 27)*. T. Bompiani.  \n   \nSiles, I., Segura–Castillo, A., Solís, R., & Sancho, M. (2020). Folk theories of algorithmic recommendations on Spotify: Enacting data assemblages in the global South. *Big Data & Society, 7(1)*, 2053951720923377.\n\n",
    "type": "read more",
    "pageName": "materials"
  },
  {
    "index": 4,
    "title": "Le collezione dei glitch algoritmici 🇮🇹",
    "description": "",
    "imgUrl": "./cards.jpg",
    "imgUrl2": "",
    "imgDida": "",
    "resUrl": "",
    "file": "",
    "content": "\n# Glitch Cards\n\nIn elettronica, un glitch è un segnale lampo che rivela un'anomalia nel sistema. Nel mazzo di carte, che evoca i tarocchi e il loro poterre divinatorio, sono contenuti i racconti di alcuni utenti dei social media sui momenti in cui si sono resi conto della presenza di algoritmi, solitamente invisibili. \n\nLe frasi sono riportate letteralmente, per restituire il senso del discorso parlato: sono state infatti pronunciate nel corso dei focus group, condotti dal gruppo di ricerca Algocount per indagare come gli utenti italiani percepiscano il funzionamento delle piattaforme digitali. \n\nLe carte verranno conservate nelle collezioni del Museo come traccia storica, sotto forma di matrice digitale e di documento stampato. ",
    "type": "read more",
    "pageName": "materials"
  },
  {
    "index": 5,
    "title": "Data Sprint Results",
    "description": "A website collecting results of the \"Algocount Data Sprint\"",
    "imgUrl": "./datasprints.jpg",
    "imgUrl2": "",
    "imgDida": "",
    "resUrl": "./data-sprint",
    "file": "",
    "content": "\n# DataSprint Activities Report\n\nThe Algocount Datasprint was held online from January 18th to 22nd, 2021. Emulating the successful approaches of the Digital Methods Initiative Schools in Amsterdam and the Smart Data Sprint in Lisbon, all the experiments were conducted using Digital Methods. The datasprint is conducted by researchers at the University of Milan, Department of Social and Political Sciences, and Density Design, Politecnico di Milano. Participants (from University of Milan and DensityDesign) have organized themselves into five sub-groups, and, as a result, the data sprint produced a total of seven single investigations, each addressing a research question. Each group had a research leader pitching the project during the first day and guiding the investigation. During the first day of work, project leaders pitched five projects focused on Facebook, Twitter, Instagram, TikTok, Reddit, and YouTube. Participants enrolled into groups to find a balance between their skills and competencies in Communication Design and Social and Political Studies.\n\nHere, in alphabetical order, the list of researchers participating in the Algocount Datasprint: Ángeles Briones, Antonella Autuori, Irene Avossa, Laura Bruschi, Ludovica Corponi, Tommaso Elli, Alessandra Facchin, Emma Fortunati, Alessandro Gandini, Alessandro Gerosa, Giulia Giorgi, Beatrice Gobbo, Michele Grilli, Giovanni Lombardi, Vincenzo Luise, Michele Mauri, Andrea Elena Febres Medina, Riccardo Pronzato, Ilir Rama, Camilla Volpe. ",
    "type": "read more",
    "pageName": "materials"
  },
  {
    "index": 6,
    "title": "Ideas for the algorithmic public opinion 🇮🇹",
    "description": "Proposte di Policy per l’Opinione Pubblica Algoritmica",
    "imgUrl": "./ideas.jpg",
    "imgUrl2": "",
    "imgDida": "",
    "resUrl": "",
    "file": "./5PropostePolicyOpinionPubblicaAlgoritmica.pdf",
    "content": "\n# 5 Proposte di Policy per l’Opinione Pubblica Algoritmica\nL’approccio regolatorio agli algoritmi che influenzano la formazione dell'opinione pubblica è caratterizzato da un complesso sistema normativo che coinvolge diversi atti e approcci legislativi, dalla protezione dei dati alla regolamentazione delle piattaforme, dal diritto delle comunicazioni alla governance degli algoritmi. Ad oggi, non esiste ancora un vocabolario o framework condiviso per affrontare le attuali sfide algoritmiche, che comportano una trasformazione dei media stessi, a causa della loro convergenza e dell'ascesa delle piattaforme digitali su base transnazionale. Questo scenario richiede modelli innovativi per la governance digitale; nello specifico, per un'opinione pubblica algoritmica il più possibile “sana e sostenibile” c'è un profondo bisogno non solo di un nuovo modello, ma anche di riforme strutturali e di un cambio di paradigma culturale. In questi anni abbiamo assistito alla creazione di nuovi diritti, come il “diritto all’oblio”, per evitare che i dati passati influenzino negativamente il presente, oppure ancora il “diritto alla spiegazione”, per sapere come certe decisioni vengono prese utilizzando dati digitali. \n\nQuesti diritti, tuttavia, devono ancora pienamente affermarsi, e soprattutto devono essere forniti ai cittadini strumenti adeguati affinché tali diritti possano essere esercitati attivamente. Si tratta di un processo di adattamento a una rivoluzione, quella digitale, che risulta essere ancora troppo spesso lento e tortuoso. [...]\n",
    "type": "read more",
    "pageName": "materials"
  },
  {
    "index": 7,
    "title": "Policy Report",
    "description": "A report on Policy",
    "imgUrl": "./policyReport.jpg",
    "imgUrl2": "",
    "imgDida": "",
    "resUrl": "",
    "file": "./algocountD5.pdf",
    "content": "\n# Policy Report\n\nThe algocount project seeks to contribute to concerns on the political and policy implications of the rise of algorithms. The diffusion of an Algorithmic Public Opinion specifically regards the concern that algorithmic systems disrupt previous patterns of individual and public opinion formation as well as of political participation and policy formation. Few analyses explored this phenomenon throughout a multidisciplinary comprehensive policy lens. The algocount project seeks to address this gap by discussing innovative policy approaches and proposals to the challenges of the current algorithmic public opinion. In this policy review, I firstly introduce the main algorithms, concerns\nand actors involved in the algorithmic public opinion. Then, I discus the main policy approaches to the systemic challenges as well as specific proposals to the main identified algorithmic systems: recommender systems, disinformation, political microtargeting, content moderation and social bots. The ultimate goal of this analysis is to provide a critical, comprehensive and long-term oriented policy overview of the algorithmic public opinion.\n\n\n\n",
    "type": "read more",
    "pageName": "materials"
  },
  {
    "index": 8,
    "title": "Le tracce algoritmiche di Anastasio F. 🇮🇹",
    "description": "",
    "imgUrl": "./tracce.png",
    "imgUrl2": "",
    "imgDida": "",
    "resUrl": "",
    "file": "",
    "content": "\n# Le tracce agoritmiche di Anastasio F. \n\nIl grafico rappresenta l’interazione tra un nuovo utente iscritto al social network Facebook e il News Feed della piattaforma.\nIl News Feed è il cuore della pagina iniziale di Facebook.\nÈ una lista di storie che si aggiornano di continuo, create dall’utente e dai suoi “amici”.\n\nIl News Feed è un algoritmo.\nMostra all’utente solo i contenuti che si suppone siano interessanti per lui/lei, sulla base di un complesso calcolo di chi pubblica determinati contenuti, e quando. \nIl funzionamento del News Feed non è noto. \nIl tracciato è il risultato di un esperimento realizzato dal gruppo di ricerca Algocount per comprendere il comportamento del News Feed in date circostanze.\n\nI ricercatori hanno creato un utente fittizio tramite un software che genera casualmente profili: Anastasio Fiorentini, uomo, di Milano, appassionato di meme, viaggi e ascolto musicale. Anastasio è stato iscritto a Facebook.\n\nPer prima cosa, Anastasio ha effettuato una ricerca nel motore interno del social network a proposito di un tema al centro dell’opinione pubblica: la pandemia da Covid-19.\nAnastasio ha cercato la stringa “no mask”. Giorno dopo giorno, ha accettato tutti i suggerimenti proposti dal News Feed: amici, pagine da seguire e gruppi a cui iscriversi o mettere “like”. \n\nI dati delle pagine visitate sono stati raccolti ed elaborati dal gruppo di ricerca. Su questa base, due ricercatrici hanno prodotto questo grafico, che mostra il percorso dei suggerimenti proposti dall’algoritmo: in pochi giorni, il News Feed ha “immaginato” Anastasio come un utente contrario alle vaccinazioni e radicalmente critico nei confronti delle misure sanitarie attuate dal governo italiano.\n\n\n\n",
    "type": "read more",
    "pageName": "materials"
  }
]