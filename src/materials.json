[
  {
    "index": 1,
    "title": "PlacPlac",
    "description": "A new dissemination format for Digital Methods research",
    "imgUrl": "./placplac.jpg",
    "resUrl": "https://github.com/densitydesign/placplac",
    "content": "\n# PlacPlac\n\n Part of the Algocount research has been carried on during a data sprint to study the public perception of algorithms in society. To present the research result to a broader audience, we developed PlacPlac, a new dissemination format to store, stage, and access the results of data sprints after research activities. The format is based on a tool called Plaplac, which is part of a research project. The tool is intended as a digital place that allows researchers to expose the research process with digital methods. The tool emphasizes telling the research process, articulating the content that reinforces the use of images, visualizations, audiovisual material, among others.\n\n",
    "type": "read more",
    "pageName": "materials"
  },
  {
    "index": 2,
    "title": "Literature Review",
    "description": "A literature review on the public perception of algorithms ",
    "imgUrl": "./litreview.jpg",
    "resUrl": "http://placplac.densitydesign.org/login",
    "content": "\n# Literature Review\n\n",
    "type": "forthcoming",
    "pageName": "materials"
  },
  {
    "index": 3,
    "title": "Reporting Focus Groups",
    "description": "Results from five focus groups carried on during Summer 2021",
    "imgUrl": "./focusgroups.jpg",
    "resUrl": "",
    "content": "### Reporting Focus Groups\n# Focus groups: exploring the algorithmic imaginaries of Italian social media users\n*Article by Luca Giuffrè*   \n*Focus groups conducted by Silvia Keeling and Alessandro Gerosa*\n\nOne of the main goals of the ALGOCOUNT research project is to assess perception, knowledge and trust towards algorithms embedded within social media for content recommendation. In order to address this issue, the research team has conducted six focus groups involving 33 Italian social media users equally distributed in terms of gender, education and age (between 18 and 58 years old). This article aims at illustrating some of the main results emerging from the analysis.\n\n\nFor the vast majority of participants, social media represent the main gateway to access information. According to the number of accesses and time spent on them, these platforms are mostly used to keep up with the latest news and participate in peer-to-peer thematic groups (e.g. tips groups on Facebook). Although cross-checking informational sources and deep reading are generally held in online newspapers, the younger cohort is more prone to seek out affordable news online than the older participants, who still consider television as the most reliable media.\n\nNot only generational characteristics, but also personal opinions are relevant in influencing everyday informational diets on social media. As a matter of fact, subjective perceptions on these platforms tend to drive people to mistake their ideas for intrinsic features of the media itself. For example, some participants affirm that Facebook is the platform where “my parents would post onto”, that is an halfwaythrough statement between generational expectations and personal experiences.\n\nThese two aspects (generational and subjective features) set the frame into which users produce meanings, perceptions and values on social media. In fact, metrics represent a good way to observe particular values of the participants. For example, even if metrics are not considered relevant in the path of picking out online content, the social network (e.g. a friend’s name who liked a post) and relevant comments (e.g. influencers’ comments) appear to be more credible than the number of views — albeit the only exception is in the case of YouTube videos, more specifically tutorials.\n\nSimilarly, participants found it problematic to retrieve affordable news. Thus, awareness on news sources emerged as one of the most important values. Furthermore, while they reckon fake news as a relevant problem in contemporary society, participants tend to deny every kind of contact with them, although they can recall at least a story of “a friend that one day…”. In that case, sources have become a new social value through which people perceive the “Other”.\n\nThe key role of individual experiences sheds light in the second section of this article: the perception of algorithms. Above all, participants show an anecdotal awareness of algorithms mostly related to social media ads and recommended content. Furthermore, the algorithm's perception comes out as simple and — to some extent — raw, because it is almost entirely based on the “if… then” logic, that is the essential causal paradigm underneath flowcharts.\nHowever, stories told during the sessions show a variety of relationships with algorithms, mainly derived from an algorithmic acceptance threshold. More specifically, an algorithmic acceptance threshold refers to a cognitive line below which users are somehow in harmony with the algorithm, that is a low-stress and low-energy consumption relationship. Viceversa, above the threshold the human-algorithm interaction becomes conflicting and therefore highly consumptive in terms of cognitive energy.\n\nFor what concerns the observation of the algorithmic acceptance threshold, the phenomenon of *“glitches”* has been quite relevant for analytical purposes. A glitch is a peculiar event in which “something went wrong” during everyday life on social media. In those situations, people experience the presence of the recommendation algorithm and react in different ways. At this point, two main aspects emerged during the analysis: the relationship between humans and algorithms and the reactions related to their manifestation.\n\nIn order to explore the former, participants have been involved in a series of activities aimed at understanding the way through which they picture social media algorithms’ mechanism. For example, they have been asked to draw out an algorithm or to tell glitch stories as previously introduced. According to this, reference has been made to Bucher’s (2017) notion of “algorithmic imaginaries”, Siles et al.’s (2020) folk theories of algorithms and the vast research horizon that have recently implemented many theoretical approaches as well as methodologies fundamental to understanding human-algorithm interaction.\nIn this context, two main imaginaries have been observed: *human-deterministic* and *magical-anthropomorphic*. The first one, quite rare, is regulated by a causal modality of thinking, therefore the algorithm appears to be controllable and under human domain. On the other side, the most widespread cluster is typically characterised by an anthropomorphization of the algorithm, that is the perception of a quasi-human entity that decides the content seen by users. In these terms, user control over the algorithm might appear weaker. \nEventually, these imaginaries are useful to understand the agency role within the human-algorithmic relationship, although they are not closed clusters, as they still have some intersections.\n\nReactions to algorithms represent useful modalities to set a good cognitive balance towards the relationship with algorithms. In particular, glitches are relevant events that make people aware of algorithms and allow researchers to furtherly explore the consequent interaction. These have brought up two models attributable to the well-known Umberto Eco’s (1984) duality between *integrated* and *apocalyptic*. The integrated model includes individuals who reckon glitches as events in which algorithms catch users’ online behaviour improperly, giving back a faulty output. In some cases, their will of realignment has driven them to act in a way that teaches the algorithm what kind of content they want to see. Instead, in the apocalyptic model, people feel the algorithm’s glitches as an uncanny and upsetting experience, and are therefore more inclined to put exit-strategies in place. Furthermore, it is particularly interesting to observe the attempts to increase their perceived control over the platform through a system of tactics, as de Certeau would define them, aimed at coping with the algorithms. For example, by opting in the *I'm not interested* flag in order to hide specific categories of tweets or ads, using a software to disorientate the algorithm coping process, *lurking* a Facebook group as a form of non-participation.\n\nIn conclusion, the relationship with and the reaction to algorithms shed light on the relevance of algorithmic systems in regulating news circulation on social media. As a matter of fact, participants’ perception of news circulation relies in no small part on everyday interactions with algorithms. Yet, *good* information or news regarding niche themes is perceived as not fostered by these systems, whereas trending topics tend to be more related to algorithmic interventions as the algorithm is perceived to become more *precise*, regardless of the quality of the content itself. These perceptions bring up some contrasting opinions for what concerns AIs. For example, while few participants suggest algorithms should be even more efficient in terms of recommendation, others would rather systems programmed to prevent filter bubbles. Hence, they believe these should be more *democratic*, *ethical*, and *impartial*. While showing the development of contemporary public opinion, these necessities highlight the role of *black boxes* in the practice of everyday news circulation.  \n&nbsp;  \n&nbsp;    \n&nbsp;   \nBucher, T. (2017). The algorithmic imaginary: exploring the ordinary affects of Facebook algorithms. *Information, communication & society, 20(1)*, 30–44.  \n\nEco, U. (1984). *Apocalittici e integrati (Vol. 27)*. T. Bompiani.  \n   \nSiles, I., Segura–Castillo, A., Solís, R., & Sancho, M. (2020). Folk theories of algorithmic recommendations on Spotify: Enacting data assemblages in the global South. *Big Data & Society, 7(1)*, 2053951720923377.\n\n",
    "type": "read more",
    "pageName": "materials"
  },
  {
    "index": 4,
    "title": "Glitch Cards",
    "description": "A collection of cards from algorithmic situations",
    "imgUrl": "./cards.jpg",
    "resUrl": "",
    "content": "\n# GlitchCards\nDummy text hola hola ",
    "type": "forthcoming",
    "pageName": "materials"
  },
  {
    "index": 5,
    "title": "Data Sprint Results",
    "description": "A website collecting results of the \"Algocount Data Sprint\"",
    "imgUrl": "./datasprints.jpg",
    "resUrl": "./data-sprint/index.html",
    "content": "\n# DataSprint Activities Report\n\nThe Algocount Datasprint was held online from January 18th to 22nd, 2021. Emulating the successful approaches of the Digital Methods Initiative Schools in Amsterdam and the Smart Data Sprint in Lisbon, all the experiments were conducted using Digital Methods. The datasprint is conducted by researchers at the University of Milan, Department of Social and Political Sciences, and Density Design, Politecnico di Milano. Participants (from University of Milan and DensityDesign) have organized themselves into five sub-groups, and, as a result, the data sprint produced a total of seven single investigations, each addressing a research question. Each group had a research leader pitching the project during the first day and guiding the investigation. During the first day of work, project leaders pitched five projects focused on Facebook, Twitter, Instagram, TikTok, Reddit, and YouTube. Participants enrolled into groups to find a balance between their skills and competencies in Communication Design and Social and Political Studies.\n\nHere, in alphabetical order, the list of researchers participating in the Algocount Datasprint: Ángeles Briones, Antonella Autuori, Irene Avossa, Laura Bruschi, Ludovica Corponi, Tommaso Elli, Alessandra Facchin, Emma Fortunati, Alessandro Gandini, Alessandro Gerosa, Giulia Giorgi, Beatrice Gobbo, Michele Grilli, Giovanni Lombardi, Vincenzo Luise, Michele Mauri, Andrea Elena Febres Medina, Riccardo Pronzato, Ilir Rama, Camilla Volpe. ",
    "type": "read more",
    "pageName": "materials"
  },
  {
    "index": 6,
    "title": "Ideas for the algorithmic public opinion",
    "description": "No description given",
    "imgUrl": "./ideas.jpg",
    "resUrl": "",
    "content": "\n# Ideas for the algorithmic public opinion\n",
    "type": "forthcoming",
    "pageName": "materials"
  },
  {
    "index": 7,
    "title": "Policy Report",
    "description": "A report on Policy",
    "imgUrl": "./policyreport.jpg",
    "resUrl": "",
    "content": "\n# Policy Report\n\n",
    "type": "forthcoming",
    "pageName": "materials"
  }
]